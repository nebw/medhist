model_type: 'MLP'
dropout: 0.2
kwargs:
  num_hidden: 256
  num_layers: 2
  detach_clf: False
  initial_dropout: 0.
  initial_norm: True
  use_final_layer_bias: True
